{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# HW2B - NumPy Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "See Canvas for details on how to complete and submit this assignment.\n",
    "\n",
    "**Note: if you are reading this on Colab, Stop! Follow the instructions on Canvas to load and run this notebook locally.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "This assignment marks your transition from cloud-based notebooks to local development. You'll apply the terminal skills and conda environment from HW2A to run NumPy computations on your own machine, experiencing firsthand another way that professional data scientists actually work.\n",
    "\n",
    "Through three progressively complex problems — temperature monitoring, grade analysis, and sales performance — you'll discover why NumPy underpins nearly every Python data science tool you'll encounter. These aren't toy problems: they represent patterns you'll use repeatedly when cleaning sensor data, analyzing experimental results, or processing business metrics.\n",
    "\n",
    "The assignment deliberately contrasts NumPy's vectorized operations with traditional Python loops. You'll measure actual performance differences on your hardware and develop intuition for when NumPy should be employed. By the end, you'll see why operations that take minutes with pure Python complete in milliseconds with NumPy.\n",
    "\n",
    "This assignment should take 2-3 hours to complete, 3-4 for Graduate students with additional requirements.\n",
    "\n",
    "Before submitting, ensure your notebook:\n",
    "\n",
    "- Runs completely with \"Kernel → Restart & Run All\"\n",
    "- Includes all required pasted outputs in markdown cells\n",
    "- Uses clear variable names, includes docstrings, and is readable by others\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By completing this assignment, you will be able to:\n",
    "\n",
    "1. **Execute NumPy operations in a local environment**\n",
    "   - Navigate Jupyter Lab interface and conda environment activation\n",
    "   - Troubleshoot import errors and version conflicts\n",
    "   - Compare local vs. cloud development tradeoffs\n",
    "\n",
    "2. **Manipulate arrays using NumPy's indexing paradigms**\n",
    "   - Extract data using basic slicing, boolean masks, and fancy indexing\n",
    "   - Distinguish operations that create views vs. copies\n",
    "   - Apply `np.where()` for both location finding and conditional selection\n",
    "\n",
    "3. **Leverage broadcasting for efficient computations**\n",
    "   - Eliminate explicit loops using vectorized operations\n",
    "   - Predict output shapes from broadcast operations\n",
    "   - Apply broadcasting rules to normalize data across axes\n",
    "\n",
    "4. **Measure and interpret performance characteristics**\n",
    "   - Use `%timeit` to benchmark operations at different scales\n",
    "   - Calculate and explain speedup factors\n",
    "   - Identify the data size threshold where NumPy becomes essential\n",
    "\n",
    "5. **Connect NumPy patterns to real applications**\n",
    "   - Recognize when to use `clip()`, `percentile()`, and other domain-specific ufuncs\n",
    "   - Choose between `np.where()`, `np.select()`, and boolean indexing for filtering\n",
    "   - Explain why method chaining drives NumPy's design philosophy\n",
    "\n",
    "### Generative AI Allowance\n",
    "\n",
    "You may use GenAI tools for brainstorming, explanations, and code sketches if you disclose it, understand it, and validate it. Your submission must represent your own work and you are solely responsible for its correctness.\n",
    "\n",
    "### Scoring\n",
    "\n",
    "- Problem 1: 25 pts\n",
    "- Problem 2: 30 pts\n",
    "- Problem 3: 15 pts\n",
    "- Reflection: 10 pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Problem 1: Temperature Data Analysis (Detailed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Run the following code to generate synthetic hourly temperature readings for one week. Rows represent days (0=Monday through 6=Sunday), columns represent hours (0-23)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Provided code to generate the data\n",
    "np.random.seed(42)\n",
    "base_temps = 70 + 15 * np.sin(np.linspace(0, 2*np.pi, 24))  # Daily cycle\n",
    "weekly_variation = np.array([0, 2, 4, 3, 1, -2, -3])[:, np.newaxis]  # Weekly trend\n",
    "noise = np.random.randn(7, 24) * 3  # Random variation\n",
    "temperatures = base_temps + weekly_variation + noise\n",
    "temperatures = np.round(temperatures, 1)  # Round to 1 decimal\n",
    "print(temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Task 1a: Array Properties\n",
    "\n",
    "Report the basic properties of the temperature array: its type, number of dimensions, shape, total size, and the data type of its elements. Format your output as \"property name: property value\", e.g., `Data type: int8`, with each property on a separate line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1a code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Task 1b: Basic Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Extract and print the following subsets of data:\n",
    "\n",
    "- All of Monday's temperatures\n",
    "- The temperature at noon for every day of the week\n",
    "- The weekend temperatures\n",
    "\n",
    "Format your output as you did in part 1a, but with the name and value on separate lines, e.g.:\n",
    "\n",
    "```text\n",
    "Monday temperatures:\n",
    "<values>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1b code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Task 1c: Finding Extremes\n",
    "\n",
    "Find the single hottest temperature in the dataset. Use `np.where()` to identify exactly when it *first* occurred. Report in the format: 'Hottest temperature: X°F on Day Y at Hour Z', where Y is the day number converted to its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1c code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Reflect on this problem and answer the following questions in the markdown cell that follows.\n",
    "\n",
    "1. What is the relationship between `shape`, `ndim`, and `size`? Could you have predicted two of these if you only knew one?\n",
    "2. Compare the slicing operations you performed. Which returned 1D vs 2D arrays and why? How does NumPy decide the dimensionality of a slice?\n",
    "3. Why was `np.where` necessary to find the hottest hour? What would go wrong if you just used `temperatures.max()` alone?\n",
    "4. If you wanted to safely modify Monday's temperatures without affecting the original array, what would you need to do differently?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "*problem 1 interpretation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Follow-Up (Graduate Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Extract temperature readings for 'business hours' (9 AM - 5 PM) on weekdays only (Monday-Friday) in a single slicing operation. Then calculate and report:\n",
    "\n",
    "1. The mean temperature during business hours.\n",
    "2. The mean temperature during non-business hours on M-F.\n",
    "3. Is difference in the means greater than 1 standard deviation of all temperatures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1 follow-up code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Problem 2: Student Grade Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### Task 2a: Generate Base Scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Create a 10×5 grade array where the base score for each student-assignment pair equals: `(student_number × assignment_number × 5) + 40`. For example, Student 3's score on Assignment 2 should start as `(3 × 2 × 5) + 40 = 70`.\n",
    "\n",
    "Leverage NumPy's design to implement it in three lines of code, as follows:\n",
    "\n",
    "1. Create a column vector (i.e., shape of n, 1) called `student_nums` with values from `1` to `10` using `arange` and `reshape`.\n",
    "2. Create a row vector (i.e., shape of 1, m) called `assignment_nums` with values from `1` to `5`\n",
    "3. Calculate `base_scores` as defined above.\n",
    "\n",
    "Output the results as shown below.\n",
    "\n",
    "```text\n",
    "Base scores shape: (10, 5)\n",
    "First student scores: [45 50 55 60 65]\n",
    "Last student scores: [ 90 140 190 240 290]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup code - do not change\n",
    "np.random.seed(100)\n",
    "\n",
    "# task 2a code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### Task 2b: Add Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Add random noise to make scores \"realistic.\" Generate random values between -15 and +5 using `np.random.uniform`, then add them to base scores. Ensure no score exceeds 100 using `np.clip`. Calculate and report the minimum, maximum, mean, and standard deviation of final scores using NumPy array methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2b code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "#### Task 2c: Calculate Statistics by Axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Calculate and display:\n",
    "\n",
    "- Each student's average across all assignments (hint: use axis=1)\n",
    "- Each assignment's average across all students (hint: use axis=0)\n",
    "- Identify the hardest assignment (lowest average)\n",
    "- The number of students on honor roll (95 or better, no rounding).\n",
    "\n",
    "Use the provided `print_vals` function to display the results for student and assignment averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup code - do not change\n",
    "def print_vals(array, descr):\n",
    "    \"\"\"prints each value in an array as a line in the format\n",
    "    `descr idx: value`\n",
    "    \"\"\"\n",
    "    for idx, val in enumerate(array):\n",
    "        print(f\" {descr} {idx + 1}: {val:.1f}\")\n",
    "\n",
    "# task 2c code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Reflect on this problem and answer the following questions in the markdown cell that follows.\n",
    "\n",
    "1. In Task 2a, what NumPy feature allowed you to multiply a (10,1) array by a (5,) array? Briefly describe the process that happens \"under the hood\".\n",
    "2. How was `np.clip` useful and where would you expect to use it in other data science applications? What questions should you ask before using it?\n",
    "3. Compare using `axis=0` vs `axis=1` for the mean. How do you remember which axis does what?\n",
    "4. Why is the method syntax (e.g., `data.method()`) preferred over the function syntax (e.g., `np.method(data)`) in NumPy and how does that relate to its reliance on returned values instead of in-place modification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "*problem 2 interpretation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "#### Follow-Up (Graduate Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Apply a curve to normalize each assignment to a target mean of 75. Follow these steps to leverage vectorized operations in NumPy and avoid explicit loops:\n",
    "\n",
    "1. Create a copy of your result from 2a using the `copy()` method.\n",
    "2. Get the `current_means` for all assignments by specifying the correct axis for the `mean` method.\n",
    "3. Calculate the `shifts` for all assignments (`75 - current_means`)\n",
    "4. Add those `shifts` to the copy you created in step 1.\n",
    "5. Use `clip` to ensure scores remain in `[0, 100]`.\n",
    "\n",
    "Report the new assignment averages to verify the curve worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p2 follow-up code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Problem 3: Sales Data Filtering and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Run the following code to generate synthetic daily sales data for a retail store over one year (365 days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup code - do not modify!\n",
    "np.random.seed(200)\n",
    "\n",
    "days = np.arange(365)\n",
    "base_sales = 1000 + 300 * np.sin(2 * np.pi * days / 365 - np.pi/2)\n",
    "weekly_boost = np.where(days % 7 >= 5, 1.3, 1.0)  # 30% boost on weekends\n",
    "noise = np.random.normal(0, 100, 365)\n",
    "daily_sales = base_sales * weekly_boost + noise\n",
    "special_days = np.random.choice(365, 10, replace=False)\n",
    "daily_sales[special_days] *= np.random.uniform(1.5, 2.5, 10)\n",
    "daily_sales = np.round(daily_sales, 0)\n",
    "daily_sales = np.maximum(daily_sales, 0)\n",
    "\n",
    "print(f\"Sales data shape: {daily_sales.shape}\")\n",
    "print(f\"Sales range: ${daily_sales.min():.0f} to ${daily_sales.max():.0f}\")\n",
    "print(f\"Mean daily sales: ${daily_sales.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Run the following cell to use matplotlib to generate a histogram of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create histogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(daily_sales, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(daily_sales.mean(), color='red', linestyle='--', label=f'Mean: ${daily_sales.mean():.0f}')\n",
    "plt.axvline(daily_sales.mean() + 2*daily_sales.std(), color='orange', linestyle='--', label=f'+2σ: ${daily_sales.mean() + 2*daily_sales.std():.0f}')\n",
    "plt.xlabel('Daily Sales ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Daily Sales')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Also show time series to see the seasonal pattern\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(daily_sales, linewidth=0.5)\n",
    "plt.xlabel('Day of Year')\n",
    "plt.ylabel('Daily Sales ($)')\n",
    "plt.title('Daily Sales Throughout Year')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "#### Task 3a: Identify Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Use Boolean indexing to identify and analyze outlier days:\n",
    "\n",
    "1. Create a Boolean mask for days with sales > 2 standard deviations above the mean\n",
    "2. Count how many outlier days exist\n",
    "3. Calculate what percentage of total annual revenue came from these outlier days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3a code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "#### Task 3b: Weekend Analysis with Fancy Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Use fancy indexing to analyze weekend vs weekday performance:\n",
    "\n",
    "0. Working from the `days` array created in setup...\n",
    "1. Create an array of `weekday_indices`: indices of `days` where the day-of-week is 0-4 (Mon-Fri)\n",
    "2. Create an array of `weekend_indices`: indices of `days` where the day-of-week is 5-6 (Sat-Sun)\n",
    "3. Use those index arrays to extract `weekday_sales` and `weekend_sales`.\n",
    "4. Report the mean, median, and maximum sales for each day type.\n",
    "\n",
    "For steps 1 and 2, consider this guidance:\n",
    "\n",
    "- Recall that the mod operator (`%`) gives us the remainder of a division, which is useful for conversion\n",
    "- Use `days % 7` to get day-of-week (0=Mon, 1=Tue, ..., 6=Sun)\n",
    "- Compare that result various values to get a Boolean array, e.g. `days % 7 < 5` is `True` for all weekdays\n",
    "- `np.where()` of a Boolean array returns a tuple. Each element of the tuple is an array of indices where the Boolean array is `True`. The tuple will contain one array for each dimension in the input data. In our case the input data is 1D, so the output is a tuple of length 1. To get the array only, extract it with indexing.\n",
    "- Use the resulting array of indices for step 3.\n",
    "\n",
    "It may be helpful to build this expression one step at a time in a series of cells, so you can observe the output of each operation and check the shape, type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3b code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "#### Task 3c: Performance Analysis with Ufuncs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "Run the following code to compare two approaches - basic Python loop and Numpy's `where` - for applying dynamic pricing rules:\n",
    "\n",
    "- 20% discount on days with sales below median\n",
    "- 5% premium on days with sales above 75th percentile  \n",
    "- No change for days in between\n",
    "\n",
    "Notes:\n",
    "\n",
    "- It may take a minute for this to run on your machine. Be patient.\n",
    "- If you get an error about missing `psutil` when running this, add it to your conda environment using the methods described in the conda lecture and applied in HW2a. You may need to reopen this notebook after doing so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load module for timing execution and record starting time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# report information about your machine, loading required dependencies\n",
    "import platform\n",
    "import psutil\n",
    "\n",
    "# Report machine stats\n",
    "print(\"=== Machine Information ===\")\n",
    "print(f\"Processor: {platform.processor() or platform.machine()}\")\n",
    "print(f\"CPU cores: {psutil.cpu_count(logical=False)} physical, {psutil.cpu_count(logical=True)} logical\")\n",
    "print(f\"RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "print(f\"Python: {platform.python_version()}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(\"=\"*28 + \"\\n\")\n",
    "\n",
    "# Calculate thresholds\n",
    "median_sales = np.median(daily_sales)\n",
    "q75_sales = np.percentile(daily_sales, 75)\n",
    "\n",
    "print(f\"Median sales: ${median_sales:.2f}\")\n",
    "print(f\"75th percentile: ${q75_sales:.2f}\")\n",
    "\n",
    "# Approach 1: Pure Python loop\n",
    "def apply_pricing_loop(sales):\n",
    "    result = np.empty_like(sales)\n",
    "    for i in range(len(sales)):\n",
    "        if sales[i] < median_sales:\n",
    "            result[i] = sales[i] * 0.8  # 20% discount\n",
    "        elif sales[i] > q75_sales:\n",
    "            result[i] = sales[i] * 1.05  # 5% premium\n",
    "        else:\n",
    "            result[i] = sales[i]  # no change\n",
    "    return result\n",
    "\n",
    "# Approach 2: Nested np.where\n",
    "def apply_pricing_where(sales):\n",
    "    # Apply conditions from innermost to outermost\n",
    "    result = np.where(sales < median_sales, \n",
    "                     sales * 0.8,  # condition true\n",
    "                     np.where(sales > q75_sales,  # condition false, check next\n",
    "                             sales * 1.05,  # nested true\n",
    "                             sales))  # nested false\n",
    "    return result\n",
    "\n",
    "# Verify all methods produce identical results\n",
    "result_loop = apply_pricing_loop(daily_sales)\n",
    "result_where = apply_pricing_where(daily_sales)\n",
    "\n",
    "print(f\"\\nResults match:\")\n",
    "print(f\"  Loop vs where: {np.allclose(result_loop, result_where)}\")\n",
    "\n",
    "# Show a sample of transformations\n",
    "sample_idx = [0, 100, 200, 300]\n",
    "print(f\"\\nSample transformations:\")\n",
    "for idx in sample_idx:\n",
    "    orig = daily_sales[idx]\n",
    "    new = result_where[idx]\n",
    "    ratio = new/orig\n",
    "    print(f\"  Day {idx}: ${orig:.0f} → ${new:.0f} ({ratio:.2f}x)\")\n",
    "\n",
    "# Performance testing on original array\n",
    "print(f\"\\nTiming on 365-day array:\")\n",
    "%timeit apply_pricing_loop(daily_sales)\n",
    "%timeit apply_pricing_where(daily_sales)\n",
    "\n",
    "# Create larger array for more dramatic comparison\n",
    "np.random.seed(42)\n",
    "large_sales = np.random.normal(1000, 200, 36500)\n",
    "large_sales = np.maximum(large_sales, 0)  # no negative sales\n",
    "\n",
    "print(f\"\\nTiming on 36,500-day array (100 years):\")\n",
    "%timeit apply_pricing_loop(large_sales)\n",
    "%timeit apply_pricing_where(large_sales)\n",
    "\n",
    "# Calculate speedup factors\n",
    "import timeit\n",
    "\n",
    "# Time each approach on large array (proper timing for calculation)\n",
    "loop_time = timeit.timeit(\n",
    "    'apply_pricing_loop(large_sales)', \n",
    "    globals=globals(), \n",
    "    number=100\n",
    ") / 100\n",
    "\n",
    "where_time = timeit.timeit(\n",
    "    'apply_pricing_where(large_sales)', \n",
    "    globals=globals(), \n",
    "    number=100\n",
    ") / 100\n",
    "\n",
    "print(f\"\\nSpeedup factors (on 100-year data):\")\n",
    "print(f\"  np.where is {loop_time/where_time:.1f}x faster than loop\")\n",
    "print(f\"\\nTotal cell execution time: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "After running the code, answer these questions in the markdown block below:\n",
    "\n",
    "1. Copy and paste your results to the [Canvas discussion board](https://auburn.instructure.com/courses/1665637/discussion_topics/10108405) and review those posted by others in the class. How long did it take for it to run on your machine (see last line of output)? Compare that result with some from your classmates. How does performance vary by hardware (see the machine info section)?\n",
    "2. Compare the calculated speedup factor on 100-year data with the same for 1 year data (you will need to calculate it). What does this tell you?\n",
    "3. So far, we've only used `np.where` to return True / False values, but it is much more powerful than that. Look at the `np.where` implementation and do some research on the function. Explain in your own words how the nested structure works. Does this remind you of anything in Excel?\n",
    "4. Review the code provided. Identify 3 other things you learned from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "*problem 3c answers here here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "Reflect on this problem and answer the following questions in the markdown cell that follows.\n",
    "\n",
    "1. Did you use Boolean indexing (i.e., `some_array[boolean_mask]`) to subset data in task 3a? If so, how and why? If not, how could your solution be improved / simplified with it?\n",
    "2. Explain, in your own words, the process used to generate the array of indexes for \"fancy indexing\" in task 3b.\n",
    "3. What surprised you most about the performance results in 3c?\n",
    "4. How can you use the original graphs to validate your findings? Does anything seem out of line?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "*problem 3 interpretation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## Reflection (10 points)\n",
    "\n",
    "Address the following in a markdown cell:\n",
    "\n",
    "1. **Local Development Experience** (3 points)\n",
    "   - Describe what, if any, relevant prior experience you have with terminal commands, conda, virtual environments, etc. This will help us interpret the feedback that follows.\n",
    "   - What specific challenges did you encounter moving from Colab to local Jupyter Lab, if any? How did you solve them?\n",
    "   - Compare the experience: What do you miss about Colab? What do you prefer about local development?\n",
    "   - Give some feedback on the style of instruction for terminal, conda, etc. Was the material sufficient, etc.?\n",
    "\n",
    "2. **NumPy Conceptual Understanding** (3 points)\n",
    "   - If you've used MATLAB, R, or another scientific computing platform, how does NumPy compare?\n",
    "   - Which NumPy concept most changed how you think about data manipulation?\n",
    "   - Based on your timing results in Problem 3c, at what data size would you say NumPy becomes \"worth it\"?\n",
    "\n",
    "3. **Terminal & Environment Management** (3 points)\n",
    "   - Which terminal commands did you use most frequently while working on this assignment?\n",
    "\n",
    "4. **Meta-Learning & Feedback** (1 point)\n",
    "   - Time spent: ___ (broken down by: setup/environment: ___, coding: ___, debugging: ___)\n",
    "   - Most frustrating technical issue and how you resolved it: ___\n",
    "   - One specific improvement for the assignment instructions: ___\n",
    "   - On a scale of 1-10, how prepared do you feel to use NumPy in your own projects? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "*reflection here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INSY6500-Py4EDA",
   "language": "python",
   "name": "insy6500-py4eda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
