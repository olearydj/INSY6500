{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# GroupBy Advanced & Merge/Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "This lecture extends our groupby knowledge and introduces data combination techniques:\n",
    "\n",
    "1. GroupBy Advanced Patterns: `transform()` and `apply()` for complex operations\n",
    "2. Merge and Join: Combining DataFrames based on common keys\n",
    "\n",
    "These are essential patterns for real data analysis where you need to:\n",
    "\n",
    "- Add group statistics back to original rows (transform)\n",
    "- Perform custom group operations (apply)\n",
    "- Combine data from multiple sources (merge/join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load diamonds dataset\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "df = diamonds.sample(n=5000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## User-Defined Functions with `agg`, `groupby`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Last lecture we learned aggregation: each group is represented as a single row with one or more statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation: many rows → one row per group\n",
    "df.groupby('cut', observed=False)['price'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Before we dive deeper, let's clarify something important: you can pass *any function* to `groupby operations` - built-in, custom named functions, or lambdas.\n",
    "\n",
    "We've seen built-in functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('cut', observed=False)['price'].mean()\n",
    "df.groupby('cut', observed=False)['price'].agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "But you can also write your own functions and pass them the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom aggregation function\n",
    "def price_range(prices):\n",
    "    \"\"\"Calculate the range (max - min) of prices\"\"\"\n",
    "    return prices.max() - prices.min()\n",
    "\n",
    "# Use it with agg\n",
    "range_by_cut = df.groupby('cut', observed=False)['price'].agg(price_range)\n",
    "print(\"Price range by cut:\")\n",
    "print(range_by_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Your function will receive a Series (each group's data, one per iteration). For `agg`, it must return a single value. Other operations will have different expectations of the return value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Lambdas are just anonymous functions - useful for one-liners but identical in concept to user defined functions.\n",
    "\n",
    "The following code blocks are equivalent implementations of \"de-meaning\" the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named function\n",
    "def subtract_mean(values):\n",
    "    return values - values.mean()\n",
    "\n",
    "result1 = df.groupby('cut', observed=False)['price'].transform(subtract_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda (anonymous function)\n",
    "result2 = df.groupby('cut', observed=False)['price'].transform(lambda x: x - x.mean())\n",
    "\n",
    "# Verify they're the same\n",
    "print(f\"Results are identical: {result1.equals(result2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "When to use each:\n",
    "\n",
    "- Built-in functions (`mean`, `sum`) wherever possible\n",
    "- Named functions for complex logic, reusable across multiple analyses, easier to test\n",
    "- Lambdas for simple one-liners that aren't reused elsewhere\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## GroupBy Advanced Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### transform(): Keep the Original Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "With `agg`, each group is reduced to a single line of output.\n",
    "\n",
    "Sometimes you want group statistics but keep all original rows. That's what transform() does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the average price for each cut as a new column\n",
    "df['avg_price_for_cut'] = df.groupby('cut', observed=False)['price'].transform('mean')\n",
    "\n",
    "# Check the result\n",
    "print(df[['cut', 'price', 'avg_price_for_cut']].head(10))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Notice:\n",
    "\n",
    "- Every row keeps its original position\n",
    "- Each row gets the average price for its cut group\n",
    "- Same shape in, same shape out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Practical Use Case: Comparing to Group Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Transform is perfect for \"how does this compare to others in its group?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how much each diamond deviates from its cut's average price\n",
    "df['price_vs_cut_avg'] = df['price'] - df.groupby('cut', observed=False)['price'].transform('mean')\n",
    "\n",
    "# Show diamonds that are much more expensive than their cut's average\n",
    "expensive_for_cut = df[df['price_vs_cut_avg'] > 5000]\n",
    "print(f\"Diamonds priced $5000+ above their cut's average: {len(expensive_for_cut)}\")\n",
    "print(\"\\nExamples:\")\n",
    "print(expensive_for_cut[['cut', 'price', 'avg_price_for_cut', 'price_vs_cut_avg']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Like `agg`, the `transform` method passes each subset of data (the rows in each group) to the chosen function, `mean`, one at a time. This is done as a loop (e.g., `for group in groups`), but the transform operation is vectorized within each group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Transform with Custom Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "As expected, you can use transform with user defined or lambda functions for custom calculations. The input is the group data, as usual, but in this case you must return all the rows, not a single statistic.\n",
    "\n",
    "The following example demonstrates this, returning a series containing the z-scores within each cut group.\n",
    "\n",
    "Below we apply this technique to add a column to the dataset and use that to find observations where the price is a within-group outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-scores within each cut group\n",
    "df['price_zscore_by_cut'] = (df\n",
    "    .groupby('cut', observed=False)['price']\n",
    "    .transform(lambda x: (x - x.mean()) / x.std())\n",
    ")\n",
    "\n",
    "# Find extreme outliers (|z| > 2)\n",
    "outliers = df[df['price_zscore_by_cut'].abs() > 2]\n",
    "print(f\"Price outliers within their cut group: {len(outliers)}\")\n",
    "print(\"\\nExamples:\")\n",
    "print(outliers[['cut', 'price', 'price_zscore_by_cut']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### When to Use transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Use transform() when you need to:\n",
    "- Add group statistics back to every row\n",
    "- Calculate within-group z-scores or percentiles\n",
    "- Compare individual values to their group\n",
    "- Keep the original DataFrame structure\n",
    "\n",
    "Don't use transform() when:\n",
    "- You just need summary statistics (use aggregation)\n",
    "- You're creating a report (use aggregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### apply(): Custom Group Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "When built-in aggregations aren't enough, use `apply()` with a custom function. Your function can return a scalar (single value per group), Series (multiple values per group), or DataFrame (multiple rows per group).\n",
    "\n",
    "In the example below `top_3_expensive` takes a group and returns the rows with the three highest prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 3 most expensive diamonds for each cut\n",
    "def top_3_expensive(group):\n",
    "    return group.nlargest(3, 'price')\n",
    "\n",
    "top_diamonds = df.groupby('cut', observed=False).apply(top_3_expensive, include_groups=False)\n",
    "print(top_diamonds[['carat', 'price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "`apply()` returns a new DataFrame with a hierarchical index - the group, then the original index.\n",
    "\n",
    "Note that `include_groups=False` is specified in `apply`. This is required to avoid more FutureWarnings about deprecated behavior and makes it explicit that *do not* want to include the group column (i.e., `cut`) in the data sent to `apply`. In the future this will be the default behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### apply() with Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "You can return summary statistics that don't fit standard aggregation patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the price range (max - min) and coefficient of variation for each cut\n",
    "def price_stats(group):\n",
    "    return pd.Series({\n",
    "        'price_range': group['price'].max() - group['price'].min(),\n",
    "        'cv': group['price'].std() / group['price'].mean(),\n",
    "        'count': len(group)\n",
    "    })\n",
    "\n",
    "custom_stats = df.groupby('cut', observed=False).apply(price_stats, include_groups=False)\n",
    "print(custom_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Performance Warning: apply() is Slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "apply() is flexible but slower than vectorized operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slow: using apply for something simple\n",
    "%timeit df.groupby('cut', observed=False).apply(lambda x: x['price'].mean(), include_groups=False)\n",
    "\n",
    "# Fast: using built-in aggregation\n",
    "%timeit df.groupby('cut', observed=False)['price'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Rule: Use built-in aggregations when possible. Only use apply() when you truly need custom logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### Summary: Choosing the Right GroupBy Method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Comparison of groupby operations:\n",
    "\n",
    "| Method | Output Shape | Use Case | Performance | When to Use |\n",
    "|--------|--------------|----------|-------------|-------------|\n",
    "| `.agg()` | One row per group | Summary statistics |  Fast | Need summary report or statistics |\n",
    "| `.transform()` | Same as input | Add group stats to each row |  Slower | Need to compare individuals to their group |\n",
    "| `.apply()` | Varies | Custom operations | Slowest | Nothing else works; complex logic |\n",
    "\n",
    "Decision Guide:\n",
    "\n",
    "- Want one number per group? → Use `.agg()`\n",
    "- Want to keep all rows? → Use `.transform()`\n",
    "- Need complex custom logic? → Use `.apply()` (but check for vectorized alternatives first!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## Merge and Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### Understanding Relational Data: Keys and Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Before learning the pandas syntax, let's understand WHY data is often split across multiple tables and HOW those tables relate to each other. This conceptual foundation will make merge and join operations intuitive rather than mysterious."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### The Problem: Data Lives in Multiple Places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Real-world data is rarely in a single table. Consider a _very simple_ online store:\n",
    "\n",
    "- Customers table: `customer_id`, `name`, `email`, `city`\n",
    "- Orders table: `order_id`, `customer_id`, `order_date`, `amount`\n",
    "- Products table: `product_id`, `name`, `price`, `category`\n",
    "\n",
    "Why separate tables instead of one giant table?\n",
    "\n",
    "- Avoid duplication (store customer info once, not on every order)\n",
    "- Different update frequencies (products change prices, orders don't)\n",
    "- Different data sources (CRM system, transaction database, inventory system)\n",
    "\n",
    "The challenge: How do we connect related data across tables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### Primary and Foreign Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "**Primary Key**: A column (or combination of columns) that uniquely identifies each row in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customers table - customer_id is the primary key\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4, 5],  # ← PRIMARY KEY (unique)\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'city': ['NYC', 'LA', 'Chicago', 'Houston', 'Phoenix']\n",
    "}).set_index('customer_id')\n",
    "print(\"Customers (customer_id is PRIMARY KEY):\")\n",
    "print(customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "**Foreign Key**: A column in one table that references the primary key in another table. It creates the link between tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orders table - customer_id is a foreign key referencing customers\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': [101, 102, 103, 104, 105, 106],\n",
    "    'customer_id': [1, 2, 2, 3, 6, 1],  # ← FOREIGN KEY (references customers)\n",
    "    'amount': [250, 180, 420, 310, 150, 290]\n",
    "}).set_index('order_id')\n",
    "print(\"\\nOrders (customer_id is FOREIGN KEY):\")\n",
    "print(orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "Notice: \n",
    "\n",
    "- Customer 2 (Bob) appears twice in orders - he placed multiple orders\n",
    "- Customer 6 appears in orders but doesn't exist in customers (data quality issue!)\n",
    "- Customers 4 and 5 have no orders\n",
    "\n",
    "This is where merge/join operations help us connect the tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### Relationship Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Understanding the relationship between tables helps you predict what merge operations will produce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "#### One-to-One (1:1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Each row in Table A matches exactly one row in Table B. For example, Customers and Loyalty Profiles - each customer has one loyalty profile and each loyalty profile belongs to one customer.\n",
    "\n",
    "1:1 relationships are unusual in practice - you would often just add these columns to the original table.\n",
    "\n",
    "Use separate tables when the data comes from different systems or has different update patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "#### One-to-Many (1:M) or Many-to-One (M:1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "Each row in Table A can match multiple rows in Table B.\n",
    "\n",
    "This is the *most common* relationship type in real data.\n",
    "\n",
    "Example: Customers and orders (1:M, one customer can place many orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Customers (the 'one' side):\")\n",
    "print(customers[['name']].head(3))\n",
    "print(\"\\nOrders (the 'many' side):\")\n",
    "print(orders[['customer_id', 'amount']].head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "The relationship between customers and orders is represented by copying the primary key from the \"one side\" as a foreign key on the \"many side.\" Hence, orders includes `customer_id` as a reference (foreign key) to the customer table.\n",
    "\n",
    "Customer 1 (Alice) has orders: 101, 106\n",
    "\n",
    "Customer 2 (Bob) has orders: 102, 103\n",
    "\n",
    "Customer 3 (Charlie) has orders: 104"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "#### Many-to-Many (M:N)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "Each row in Table A can match multiple rows in Table B, and vice versa.\n",
    "\n",
    "Example: Students and Courses (M:N, one student takes many courses, one course has many students)\n",
    "\n",
    "Problem: You can't directly merge students and courses - there's no common key that makes sense!\n",
    "\n",
    "Solution: Create a *junction table* (also called association table or bridge table) that connects them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot directly merge students and courses - no common key!\n",
    "# Solution: junction table\n",
    "\n",
    "students = pd.DataFrame({\n",
    "    'student_id': [1, 2, 3],\n",
    "    'name': ['Alice', 'Bob', 'Charlie']\n",
    "})\n",
    "\n",
    "courses = pd.DataFrame({\n",
    "    'course_id': [101, 102, 103],\n",
    "    'course_name': ['Math', 'Physics', 'Chemistry']\n",
    "})\n",
    "\n",
    "# Junction table connects them\n",
    "enrollments = pd.DataFrame({\n",
    "    'student_id': [1, 1, 2, 2, 3, 3],\n",
    "    'course_id': [101, 102, 101, 103, 102, 103],\n",
    "    'grade': ['A', 'B', 'A', 'C', 'B', 'A']\n",
    "})\n",
    "print(enrollments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "Now we can connect students → enrollments → courses to get complete information. Pandas implements this via the `merge` and `join` methods, which we'll cover shortly.\n",
    "\n",
    "Note that the junction table can also include information about the association, in this case the student-course grade, which is only relevant in the context of that relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "### Relationship Types Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "| Type | Example | Key Pattern | Merge Behavior |\n",
    "|------|---------|-------------|----------------|\n",
    "| 1:1 | Customer → Loyalty Profile | One FK value per row on both sides | Simple, rarely used |\n",
    "| 1:M | Customer → Orders | One PK matches many FK values | Most common, inner/left/right matter |\n",
    "| M:N | Students ↔ Courses | Requires junction table | Chain multiple merges |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "### Why This Matters for Pandas Merge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "Understanding relationships helps you:\n",
    "\n",
    "1. Choose the right approach to designing and joining tables\n",
    "2. Predict the output size:\n",
    "   - 1:1 merge: Same number of rows as input (if all match)\n",
    "   - 1:M merge: Number of rows = number on the \"many\" side\n",
    "   - M:N: Requires junction table, can explode rows\n",
    "3. Spot data quality issues:\n",
    "   - Foreign key values with no matching primary key (orphaned records)\n",
    "   - Unexpected duplicates in what should be 1:1\n",
    "\n",
    "Now that you understand HOW tables relate, pandas merge operations will make intuitive sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "### Creating Example Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "Let's create simple datasets to demonstrate merge operations clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer data\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'city': ['NYC', 'LA', 'Chicago', 'Houston', 'Phoenix']\n",
    "})\n",
    "\n",
    "# Order data\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': [101, 102, 103, 104, 105, 106],\n",
    "    'customer_id': [1, 2, 2, 3, 6, 1],\n",
    "    'amount': [250, 180, 420, 310, 150, 290]\n",
    "})\n",
    "\n",
    "print(\"Customers:\")\n",
    "print(customers)\n",
    "print(\"\\nOrders:\")\n",
    "print(orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "Notice:\n",
    "\n",
    "- Customer 4 (Diana) and 5 (Eve) have no orders\n",
    "- Customer 6 in orders doesn't exist in customers table\n",
    "- Customer 1 (Alice) has multiple orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "### Inner Join: Only Matching Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "Inner join keeps only rows where the key exists in BOTH DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join (default)\n",
    "inner = pd.merge(customers, orders, on='customer_id', how='inner')\n",
    "print(inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "Result:\n",
    "- 5 orders (customer 6's order excluded because no matching customer)\n",
    "- Only customers 1, 2, 3 appear (they have orders)\n",
    "- Customers 4, 5 excluded (no orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "### Left Join: Keep All from Left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "Left join keeps ALL rows from the left DataFrame, adding matching data from right.\n",
    "\n",
    "The resulting table will have `NaN` values wherever there is no match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join\n",
    "left = pd.merge(customers, orders, on='customer_id', how='left')\n",
    "print(left)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "Result:\n",
    "- All 5 customers appear\n",
    "- Customers without orders have NaN in order columns\n",
    "- Customer 6's order excluded (not in customers table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "### Right Join: Keep All from Right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "Right join keeps ALL rows from the right DataFrame.\n",
    "\n",
    "Like left join, unmatched data will generate `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right join\n",
    "right = pd.merge(customers, orders, on='customer_id', how='right')\n",
    "print(right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "Result:\n",
    "- All 6 orders appear\n",
    "- Customer 6's order included, but customer details are NaN\n",
    "- Customers 4, 5 excluded (no orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "### Outer Join: Keep All from Both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "Outer join keeps ALL rows from BOTH DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer join\n",
    "outer = pd.merge(customers, orders, on='customer_id', how='outer')\n",
    "print(outer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "Result:\n",
    "- All customers (1-5) appear\n",
    "- All orders (including customer 6) appear\n",
    "- NaN fills gaps where data doesn't match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "### Join Behavior Summarized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "- Inner:  A ∩ B (only matching); strict - both must agree\n",
    "- Left:   All of A + matching from B; \"Keep my data (left), add theirs if it exists\"\n",
    "- Right:  All of B + matching from A; rarely used (just swap left / right and use left join)\n",
    "- Outer:  A ∪ B (everything); generous, used for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "### Merging on Different Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "Often the key column has different names in each DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create product data with different column name\n",
    "products = pd.DataFrame({\n",
    "    'product_id': [101, 102, 103],\n",
    "    'product_name': ['Widget', 'Gadget', 'Doohickey'],\n",
    "    'category': ['Tools', 'Electronics', 'Home']\n",
    "})\n",
    "\n",
    "sales = pd.DataFrame({\n",
    "    'sale_id': [1, 2, 3, 4],\n",
    "    'prod_id': [101, 102, 101, 103],\n",
    "    'quantity': [5, 3, 2, 7]\n",
    "})\n",
    "\n",
    "print(\"Products:\")\n",
    "print(products)\n",
    "print(\"\\nSales:\")\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "Here products' primary key is `product_id`, but it is referenced in sales as `prod_id`. You can specify this explicitly in the merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on different column names\n",
    "merged = pd.merge(sales, products, \n",
    "                  left_on='prod_id', \n",
    "                  right_on='product_id', \n",
    "                  how='left')\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "Note that both key columns are kept. You can drop the redundant one if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "### Merging on Multiple Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "Sometimes the unique key is a combination of columns (composite key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales data with store and date\n",
    "sales_detail = pd.DataFrame({\n",
    "    'store': ['A', 'A', 'B', 'B'],\n",
    "    'date': ['2024-01-01', '2024-01-02', '2024-01-01', '2024-01-02'],\n",
    "    'revenue': [1000, 1200, 800, 950]\n",
    "})\n",
    "\n",
    "# Inventory data\n",
    "inventory = pd.DataFrame({\n",
    "    'store': ['A', 'A', 'B'],\n",
    "    'date': ['2024-01-01', '2024-01-02', '2024-01-01'],\n",
    "    'stock': [50, 45, 30]\n",
    "})\n",
    "\n",
    "# Merge on both store AND date\n",
    "combined = pd.merge(sales_detail, inventory, on=['store', 'date'], how='left')\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "Store B on 2024-01-02 has no inventory data, so stock is NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "### Merging on Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "When the join key is in the index, you can use index parameters instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames with meaningful indexes\n",
    "prices = pd.DataFrame({\n",
    "    'product': ['Widget', 'Gadget', 'Doohickey'],\n",
    "    'price': [19.99, 49.99, 29.99]\n",
    "}).set_index('product')\n",
    "\n",
    "ratings = pd.DataFrame({\n",
    "    'product': ['Widget', 'Gadget', 'Gizmo'],\n",
    "    'rating': [4.5, 4.2, 4.8]\n",
    "}).set_index('product')\n",
    "\n",
    "print(\"Prices:\")\n",
    "print(prices)\n",
    "print(\"\\nRatings:\")\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on index\n",
    "merged = pd.merge(prices, ratings, left_index=True, right_index=True, how='outer')\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "### Simpler Index Join: .join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "For index-based joins, DataFrame.join() is simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same result, cleaner syntax\n",
    "joined = prices.join(ratings, how='outer')\n",
    "print(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "`join()` defaults to left join and uses indexes automatically.\n",
    "\n",
    "Best practice: when defining tables, set the index to the primary key, if one exists, or use the default row index if one does not. Then use the simplified `join` syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "### Handling Duplicate Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {},
   "source": [
    "When both DataFrames have columns with the same name (other than the join key), use suffixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both have 'price' column\n",
    "df1 = pd.DataFrame({\n",
    "    'product_id': [1, 2, 3],\n",
    "    'price': [10, 20, 30]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'product_id': [1, 2, 3],\n",
    "    'price': [12, 22, 32]\n",
    "})\n",
    "\n",
    "# Merge with suffixes\n",
    "merged = pd.merge(df1, df2, on='product_id', suffixes=('_old', '_new'))\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113",
   "metadata": {},
   "source": [
    "Without suffixes, you'd get 'price_x' and 'price_y' (less meaningful)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df1, df2, on='product_id')\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115",
   "metadata": {},
   "source": [
    "## concat(): Stacking DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "### When to Use concat() vs merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "Use `.concat()` when:\n",
    "\n",
    "- Combining DataFrames with identical structure (same columns)\n",
    "- Stacking monthly/regional datasets\n",
    "- Appending new data to existing data\n",
    "\n",
    "Use `.merge()` when:\n",
    "\n",
    "- Combining related but different data\n",
    "- Matching on key columns\n",
    "- Data comes from different sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "### `concat` to Stack DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "Combine DataFrames by vertically stacking rows (most common) by specifying `axis=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# January sales\n",
    "jan_sales = pd.DataFrame({\n",
    "    'date': ['2024-01-01', '2024-01-02', '2024-01-03'],\n",
    "    'revenue': [1000, 1200, 1100]\n",
    "})\n",
    "\n",
    "# February sales\n",
    "feb_sales = pd.DataFrame({\n",
    "    'date': ['2024-02-01', '2024-02-02', '2024-02-03'],\n",
    "    'revenue': [1300, 1250, 1400]\n",
    "})\n",
    "\n",
    "# Stack vertically\n",
    "all_sales = pd.concat([jan_sales, feb_sales], axis=0)\n",
    "print(all_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121",
   "metadata": {},
   "source": [
    "Notice the index is preserved from each DataFrame. Often you want to reset it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack with reset index\n",
    "all_sales_clean = pd.concat([jan_sales, feb_sales], axis=0, ignore_index=True)\n",
    "print(all_sales_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123",
   "metadata": {},
   "source": [
    "You can also stack DataFrames horizontally (side-by-side) with `axis=1`, but `merge` / `join` are typically preferred for that to ensure the rows are aligned by key values. `concat` assumes rows align by position (index), which can be problematic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "### Handling Mismatched Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125",
   "metadata": {},
   "source": [
    "When DataFrames don't have identical columns, concat fills with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different columns\n",
    "df_a = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6]\n",
    "})\n",
    "\n",
    "df_b = pd.DataFrame({\n",
    "    'B': [7, 8, 9],\n",
    "    'C': [10, 11, 12]\n",
    "})\n",
    "\n",
    "# Concat fills missing columns with NaN\n",
    "stacked = pd.concat([df_a, df_b], axis=0, ignore_index=True)\n",
    "print(stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127",
   "metadata": {},
   "source": [
    "### Practical Example: Combining Regional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "Real-world scenario: combining sales data from multiple regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional sales data\n",
    "northeast = pd.DataFrame({\n",
    "    'region': ['Northeast'] * 3,\n",
    "    'product': ['Widget', 'Gadget', 'Doohickey'],\n",
    "    'sales': [1000, 1500, 800]\n",
    "})\n",
    "\n",
    "southeast = pd.DataFrame({\n",
    "    'region': ['Southeast'] * 3,\n",
    "    'product': ['Widget', 'Gadget', 'Doohickey'],\n",
    "    'sales': [1200, 1300, 900]\n",
    "})\n",
    "\n",
    "west = pd.DataFrame({\n",
    "    'region': ['West'] * 3,\n",
    "    'product': ['Widget', 'Gadget', 'Doohickey'],\n",
    "    'sales': [1800, 2000, 1100]\n",
    "})\n",
    "\n",
    "# Combine all regions\n",
    "national = pd.concat([northeast, southeast, west], axis=0, ignore_index=True)\n",
    "print(national)\n",
    "print(f\"\\nTotal rows: {len(national)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130",
   "metadata": {},
   "source": [
    "Now you can analyze by region, product, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sales by product across all regions\n",
    "national.groupby('product')['sales'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132",
   "metadata": {},
   "source": [
    "## Real-World Example: Combining Everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133",
   "metadata": {},
   "source": [
    "Let's combine groupby, merge, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average price by cut from our diamonds sample\n",
    "cut_avg = df.groupby('cut', observed=False).agg(\n",
    "    avg_price=('price', 'mean'),\n",
    "    count=('price', 'count')\n",
    ").reset_index()\n",
    "\n",
    "print(\"Average price by cut:\")\n",
    "print(cut_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cut quality information to each diamond\n",
    "df_enriched = pd.merge(df, cut_avg, on='cut', how='left', suffixes=('', '_avg'))\n",
    "\n",
    "# Now each row knows its cut's average price\n",
    "df_enriched['premium_over_avg'] = df_enriched['price'] - df_enriched['avg_price']\n",
    "\n",
    "print(\"\\nDiamonds with biggest premium over their cut average:\")\n",
    "print(df_enriched.nlargest(5, 'premium_over_avg')[\n",
    "    ['cut', 'carat', 'price', 'avg_price', 'premium_over_avg']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Average price by cut\n",
    "sns.barplot(data=cut_avg, x='cut', y='avg_price', ax=axes[0])\n",
    "axes[0].set_title('Average Price by Cut Quality')\n",
    "axes[0].set_ylabel('Average Price ($)')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Distribution of premium over average\n",
    "sns.histplot(data=df_enriched, x='premium_over_avg', bins=50, ax=axes[1])\n",
    "axes[1].set_title('Distribution: Price vs Cut Average')\n",
    "axes[1].set_xlabel('Price - Cut Average ($)')\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', label='Average')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137",
   "metadata": {},
   "source": [
    "## Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138",
   "metadata": {},
   "source": [
    "GroupBy Advanced:\n",
    "- transform() keeps original shape, adds group stats to each row\n",
    "- apply() allows custom group operations but is slower\n",
    "- Use built-in aggregations when possible\n",
    "\n",
    "Merge and Join:\n",
    "- Inner join: only matching rows\n",
    "- Left join: all from left, matching from right\n",
    "- Right join: all from right, matching from left\n",
    "- Outer join: all from both\n",
    "- Use left_on/right_on for different column names\n",
    "- Use on=[col1, col2] for composite keys\n",
    "\n",
    "concat():\n",
    "- Vertical stacking (axis=0): combine rows\n",
    "- Horizontal stacking (axis=1): combine columns\n",
    "- Use ignore_index=True to reset index\n",
    "- Best for identical or similar structures\n",
    "\n",
    "Next lecture: Data quality, validation, and handling missing data."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "INSY6500-Py4EDA",
   "language": "python",
   "name": "insy6500-py4eda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
