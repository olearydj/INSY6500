{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Pandas Methods for Tidying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Most real-world data arrives _untidy_. Before you can analyze it, you need to reshape it into a structure that pandas can work with effectively. This lecture maps common untidy patterns to the specific pandas methods that fix them.\n",
    "\n",
    "Recall the tidy data principles:\n",
    "\n",
    "- Every row is one observation\n",
    "- Every column is one variable\n",
    "- Every cell is one value\n",
    "\n",
    "When data violates these principles, pandas operations like `groupby()`, filtering, and plotting become awkward or impossible. The solution is reshaping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## The Tidying Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Your primary reshaping tools:\n",
    "\n",
    "- `melt()` — unpivot columns into rows (wide → long)\n",
    "- `pivot()` — reshape rows into columns (long → wide)\n",
    "- `pivot_table()` — pivot with aggregation for duplicates\n",
    "- `.str.split(expand=True)` — separate combined values into columns\n",
    "\n",
    "We will work through each of the five common untidy patterns and see which tool solves each one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Pattern 1: Column Headers Are Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "This is the most common untidy pattern. Years, months, dates, or categories appear as column names instead of as values in a column.\n",
    "\n",
    "```text\n",
    "| Country | 2020 | 2021 | 2022 |\n",
    "|---------|------|------|------|\n",
    "| USA     | 100  | 110  | 120  |\n",
    "| Canada  | 80   | 85   | 90   |\n",
    "```\n",
    "\n",
    "The years are _values_ masquerading as column names. You cannot easily filter by year or plot a time series because pandas has no Year column to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the untidy data\n",
    "untidy = pd.DataFrame({\n",
    "    'Country': ['USA', 'Canada'],\n",
    "    '2020': [100, 80],\n",
    "    '2021': [110, 85],\n",
    "    '2022': [120, 90]\n",
    "})\n",
    "\n",
    "untidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### The Solution: `melt()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "The `melt()` function _unpivots_ columns into rows. Think of it as melting those wide columns down into long rows.\n",
    "\n",
    "Key parameters:\n",
    "\n",
    "- `id_vars` — columns to keep as-is (the identifiers)\n",
    "- `var_name` — name for the column that will hold the former headers\n",
    "- `value_name` — name for the column that will hold the cell values\n",
    "\n",
    "In the example, we want to convert the year column names into a new column (`Year`) with those values and the original values into a new column (`GDP`). Te rest will remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = untidy.melt(\n",
    "    id_vars='Country',\n",
    "    var_name='Year',\n",
    "    value_name='GDP'\n",
    ")\n",
    "\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Now each observation (one country in one year) is its own row. You can filter, group, and plot naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now filtering by year is trivial\n",
    "tidy[tidy['Year'] == '2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Year to integer for proper sorting/plotting\n",
    "tidy['Year'] = tidy['Year'].astype(int)\n",
    "tidy.sort_values(['Country', 'Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Pattern 5: Repeated Measures as Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "This pattern is structurally identical to Pattern 1. Trial numbers, time points, or repeated measurements appear as column headers.\n",
    "\n",
    "```text\n",
    "| Subject | Trial1 | Trial2 | Trial3 |\n",
    "|---------|--------|--------|--------|\n",
    "| A       | 12.3   | 11.8   | 12.1   |\n",
    "| B       | 15.2   | 14.9   | 15.0   |\n",
    "```\n",
    "\n",
    "The trial numbers are values that belong in a Trial column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "untidy = pd.DataFrame({\n",
    "    'Subject': ['A', 'B'],\n",
    "    'Trial1': [12.3, 15.2],\n",
    "    'Trial2': [11.8, 14.9],\n",
    "    'Trial3': [12.1, 15.0]\n",
    "})\n",
    "\n",
    "untidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Same Solution: `melt()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = untidy.melt(\n",
    "    id_vars='Subject',\n",
    "    var_name='Trial',\n",
    "    value_name='Score'\n",
    ")\n",
    "\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "You may want to clean up the Trial column to extract just the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract trial number\n",
    "tidy['Trial'] = tidy['Trial'].str.replace('Trial', '').astype(int)\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Pattern 2: Multiple Variables in One Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Two or more pieces of information are crammed into a single column, typically with a delimiter.\n",
    "\n",
    "```text\n",
    "| ID | Gender_Age |\n",
    "|----|------------|\n",
    "| 1  | M_25       |\n",
    "| 2  | F_30       |\n",
    "| 3  | M_42       |\n",
    "```\n",
    "\n",
    "Gender and Age are separate variables that need their own columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "untidy = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'Gender_Age': ['M_25', 'F_30', 'M_42']\n",
    "})\n",
    "\n",
    "untidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### The Solution: `.str.split(expand=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "The `.str` accessor provides string methods for Series. The `split()` method with `expand=True` returns a DataFrame where each split piece becomes its own column. Like `str.split` in base Python, but with new tricks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split returns a DataFrame with expand=True\n",
    "untidy['Gender_Age'].str.split('_', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign back to new columns\n",
    "untidy[['Gender', 'Age']] = untidy['Gender_Age'].str.split('_', expand=True)\n",
    "\n",
    "# Convert Age to numeric\n",
    "untidy['Age'] = untidy['Age'].astype(int)\n",
    "\n",
    "# Drop the original combined column\n",
    "tidy = untidy.drop(columns='Gender_Age')\n",
    "\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Pattern 3: Variables in Both Rows and Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "This pattern combines the previous issues. Variable names are encoded in column headers, often with multiple pieces of information.\n",
    "\n",
    "```text\n",
    "| Date       | Temp_Morning | Temp_Evening | Humidity_Morning | Humidity_Evening |\n",
    "|------------|--------------|--------------|------------------|------------------|\n",
    "| 2024-01-01 | 45           | 52           | 65               | 70               |\n",
    "| 2024-01-02 | 43           | 50           | 68               | 72               |\n",
    "```\n",
    "\n",
    "The column headers encode two things: the variable (Temp or Humidity) and the time of day (Morning or Evening)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "untidy = pd.DataFrame({\n",
    "    'Date': ['2024-01-01', '2024-01-02'],\n",
    "    'Temp_Morning': [45, 43],\n",
    "    'Temp_Evening': [52, 50],\n",
    "    'Humidity_Morning': [65, 68],\n",
    "    'Humidity_Evening': [70, 72]\n",
    "})\n",
    "\n",
    "untidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### The Solution: Multi-Step Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Complex patterns often require multiple operations. Here we need to:\n",
    "\n",
    "1. Melt to get all values in rows\n",
    "2. Split the combined column names\n",
    "3. Pivot to get variables (Temp, Humidity) back as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Melt everything\n",
    "melted = untidy.melt(\n",
    "    id_vars='Date',\n",
    "    var_name='Var_Time',\n",
    "    value_name='Value'\n",
    ")\n",
    "\n",
    "melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split the combined column\n",
    "melted[['Variable', 'Time']] = melted['Var_Time'].str.split('_', expand=True)\n",
    "\n",
    "melted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "`pivot` is essentially the inverse of `melt`. Here we want the values in the `Variable` column to become column headers, with the corresponding `Value` entries filling those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Pivot so each variable becomes a column\n",
    "tidy = melted.pivot_table(\n",
    "    index=['Date', 'Time'],\n",
    "    columns='Variable',\n",
    "    values='Value'\n",
    ").reset_index()\n",
    "\n",
    "# Clean up the column names\n",
    "tidy.columns.name = None\n",
    "\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Now each row is one observation (one date at one time of day), and each variable (Temp, Humidity) has its own column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## Pattern 4: Multiple Observation Types in One Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Values and their labels are stored together, often from data entry systems.\n",
    "\n",
    "```text\n",
    "| ID | Measurement  |\n",
    "|----|--------------|\n",
    "| 1  | Height: 5.8  |\n",
    "| 1  | Weight: 180  |\n",
    "| 1  | Age: 30      |\n",
    "| 2  | Height: 6.1  |\n",
    "| 2  | Weight: 195  |\n",
    "| 2  | Age: 28      |\n",
    "```\n",
    "\n",
    "The Measurement column contains both the variable name and the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "untidy = pd.DataFrame({\n",
    "    'ID': [1, 1, 1, 2, 2, 2],\n",
    "    'Measurement': ['Height: 5.8', 'Weight: 180', 'Age: 30',\n",
    "                    'Height: 6.1', 'Weight: 195', 'Age: 28']\n",
    "})\n",
    "\n",
    "untidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### The Solution: Split then Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the measurement column\n",
    "untidy[['Variable', 'Value']] = untidy['Measurement'].str.split(': ', expand=True)\n",
    "\n",
    "# Convert Value to numeric\n",
    "untidy['Value'] = pd.to_numeric(untidy['Value'])\n",
    "\n",
    "untidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot so each measurement type becomes a column\n",
    "tidy = untidy.pivot(\n",
    "    index='ID',\n",
    "    columns='Variable',\n",
    "    values='Value'\n",
    ").reset_index()\n",
    "\n",
    "# Clean up column names\n",
    "tidy.columns.name = None\n",
    "\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## The Inverse: `pivot()` for Long to Wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Sometimes data arrives in an overly long format, or you need to restructure for a specific analysis. The `pivot()` function reshapes from long to wide, the opposite of `melt()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long format data\n",
    "long_data = pd.DataFrame({\n",
    "    'Store': ['A', 'A', 'B', 'B'],\n",
    "    'Quarter': ['Q1', 'Q2', 'Q1', 'Q2'],\n",
    "    'Sales': [100, 120, 80, 95]\n",
    "})\n",
    "\n",
    "long_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to wide format\n",
    "wide_data = long_data.pivot(\n",
    "    index='Store',\n",
    "    columns='Quarter',\n",
    "    values='Sales'\n",
    ")\n",
    "\n",
    "wide_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### `pivot()` vs `pivot_table()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Use `pivot()` when your index/column combination is unique (no duplicates). If duplicates exist, you need `pivot_table()` which can aggregate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with duplicates\n",
    "data_with_dupes = pd.DataFrame({\n",
    "    'Store': ['A', 'A', 'A', 'B'],\n",
    "    'Quarter': ['Q1', 'Q1', 'Q2', 'Q1'],  # Store A has two Q1 entries\n",
    "    'Sales': [100, 50, 120, 80]\n",
    "})\n",
    "\n",
    "data_with_dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot() would fail here - use pivot_table() with an aggregation function\n",
    "wide = data_with_dupes.pivot_table(\n",
    "    index='Store',\n",
    "    columns='Quarter',\n",
    "    values='Sales',\n",
    "    aggfunc='sum'  # or 'mean', 'count', etc.\n",
    ")\n",
    "\n",
    "wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## Decision Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "When you encounter untidy data, ask these questions:\n",
    "\n",
    "| If you see...                                               | Use...                                               |\n",
    "| ----------------------------------------------------------- | ---------------------------------------------------- |\n",
    "| Column headers that are really values (years, trials, etc.) | `melt()`                                             |\n",
    "| Multiple variables crammed into one column                  | `.str.split(expand=True)`                            |\n",
    "| Data that is too long and needs columns                     | `pivot()` or `pivot_table()`                         |\n",
    "| Complex encoding in column names                            | Multiple steps: `melt()` → `str.split()` → `pivot()` |\n",
    "\n",
    "The pattern recognition comes with practice. When in doubt, ask yourself: what should each row represent? What should each column represent? Then reshape to match that structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "The core tidying operations:\n",
    "\n",
    "- `melt(id_vars, var_name, value_name)` — unpivot columns to rows\n",
    "- `pivot(index, columns, values)` — reshape rows to columns\n",
    "- `pivot_table(index, columns, values, aggfunc)` — pivot with aggregation\n",
    "- `.str.split(delimiter, expand=True)` — separate combined values\n",
    "\n",
    "Most tidying involves `melt()` because human-readable formats tend to be wide. Once your data is tidy, all of pandas' analysis tools work smoothly."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "INSY6500-Py4EDA",
   "language": "python",
   "name": "insy6500-py4eda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
